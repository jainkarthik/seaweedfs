Detailed Write Operation Breakdown
ğŸŸ¦ Regular Objects (No Versioning)
Exact Write Count: 2-3 writes per PUT
PUT Request for Regular Bucket
    â†“
Write 1: Upload chunks to volume servers
    â”œâ”€â”€ HTTP POST http://volume-server:8080/{fid} for each 8MB chunk
    â”œâ”€â”€ Volume server writes to .dat file (actual data)
    â””â”€â”€ Volume server updates .idx index file (metadata)
    â†“
Write 2: Create metadata entry (filer.CreateEntry)
    â”œâ”€â”€ Location: filer metadata store (etcd/rocksdb/etc.)
    â”œâ”€â”€ Path: /buckets/mybucket/myobject.txt
    â””â”€â”€ Content: object metadata + chunk references
    â†“
Write 3 (optional): Create parent directories
    â”œâ”€â”€ Only if bucket/object path doesn't exist
    â”œâ”€â”€ Location: filer metadata store
    â””â”€â”€ Path: /buckets/mybucket/ (directory entry)
Code Evidence:
// Write 1: Upload chunks
chunkResult, err := operation.UploadReaderInChunks(ctx, dataReader, &uploadOption)
// Write 2: Create entry  
createErr := s3a.WithFilerClient(false, func(client filer_pb.SeaweedFilerClient) error {
    _, err := client.CreateEntry(context.Background(), req)  // â† Single write here
})
---
ğŸŸ¢ Versioned Objects (Versioning Enabled)
Exact Write Count: 4-6 writes per PUT
PUT Request for Versioned Bucket
    â†“
Write 1: Upload chunks to volume servers
    â”œâ”€â”€ Same as regular (HTTP POST to volume servers)
    â†“
Write 2: Create version file entry
    â”œâ”€â”€ Location: filer metadata store
    â”œâ”€â”€ Path: /buckets/mybucket/myobject.txt/.versions/versionId
    â””â”€â”€ Content: version-specific metadata + chunks
    â†“
Write 3: Update .versions directory metadata
    â”œâ”€â”€ Location: filer metadata store  
    â”œâ”€â”€ Path: /buckets/mybucket/myobject.txt/.versions/
    â””â”€â”€ Content: tracks which version is latest
    â†“
Write 4: Update latest version pointer
    â”œâ”€â”€ Location: filer metadata store
    â”œâ”€â”€ Path: /buckets/mybucket/myobject.txt
    â””â”€â”€ Content: pointer to latest version in .versions/
    â†“
Write 5 (optional): Create parent directories
    â”œâ”€â”€ Same as regular case
    â†“
Write 6 (optional): Update all other versions' IsLatest=false
    â”œâ”€â”€ Updates metadata on all existing versions
    â””â”€â”€ Ensures only new version is marked latest
Code Evidence:
// Write 2: Create version file
err = s3a.mkFile(bucketDir, versionObjectPath, versionEntry.Chunks, func(updatedEntry *filer_pb.Entry) {
    // metadata setup...
})  // â† First filer write
// Write 3+4: Update directory + latest pointer  
err = s3a.updateLatestVersionInDirectory(bucket, normalizedObject, versionId, versionFileName, versionEntry)  // â† Multiple writes here
---
ğŸŸ¡ Suspended Versioning (Versioning Disabled)
Exact Write Count: 5-7 writes per PUT
PUT Request for Suspended Bucket
    â†“
Write 1: Upload chunks to volume servers
    â”œâ”€â”€ Same as regular (HTTP POST to volume servers)
    â†“
Write 2: Delete existing null version (if exists)
    â”œâ”€â”€ Location: filer metadata store
    â”œâ”€â”€ Path: /buckets/mybucket/myobject.txt/.versions/null_version
    â””â”€â”€ Content: DELETED
    â†“
Write 3: Create null version entry
    â”œâ”€â”€ Location: filer metadata store
    â”œâ”€â”€ Path: /buckets/mybucket/myobject.txt (regular path)
    â””â”€â”€ Content: object metadata + chunks
    â†“
Write 4: Update all existing versions IsLatest=false
    â”œâ”€â”€ Location: filer metadata store
    â”œâ”€â”€ Path: /buckets/mybucket/myobject.txt/.versions/* (all versions)
    â””â”€â”€ Content: Update each version's IsLatest flag
    â†“
Write 5 (optional): Create parent directories
    â””â”€â”€ Same as regular case
    â†“
Write 6 (optional): Update .versions directory metadata
    â””â”€â”€ Maintains version history integrity
Code Evidence:
// Write 2: Delete null version
err := s3a.rm(versionsDir, entry.Name, true, false)  // â† Delete write
// Write 3: Create main entry
etag, errCode, sseMetadata := s3a.putToFiler(r, filePath, dataReader, bucket, 1)  // â† Create write
// Write 4: Update all versions
// Update All Versions to Set IsLatest=false (multiple metadata updates)
---
Storage Backend Write Summary
| Operation Type | Volume Server Writes | Filer Metadata Writes | Total Write Count |
|---|---|---|---|
| Regular PUT | 1 (per chunk) | 1-2 | 2-3 total |
| Versioned PUT | 1 (per chunk) | 3-4 | 4-5 total |
| Suspended PUT | 1 (per chunk) | 4-5 | 5-6 total |
Note: For large files split into multiple 8MB chunks, the volume server writes multiply accordingly:
- Small file (<8MB): 1 chunk â†’ 1 volume server write
- Large file (80MB): 10 chunks â†’ 10 volume server writes  
- Huge file (1GB): 128 chunks â†’ 128 volume server writes
---
Write Operation Types
Volume Server Writes (Physical data)
// Each chunk: HTTP POST to volume server
uploadUrl := fmt.Sprintf("http://%s/%s", assignResult.Url, assignResult.Fid)
uploadResult, uploadResultErr := uploader.UploadData(ctx, chunkBytes, uploadOption)
- Write to disk: .dat file
- Update index: .idx file  
- Physical storage: Persists actual bytes
Filer Metadata Writes (Logical data)
// CreateEntry/UpdateEntry/DeleteEntry â†’ filer store
_, err := client.CreateEntry(context.Background(), req)
_, err := client.DeleteEntry(context.Background(), request)
- Metadata database: etcd/rocksdb/etc.
- Path tracking: Directory/file relationships
- Chunk references: Points to volume server data
Why Multiple Writes?
1. Atomicity: Ensure data consistency across distributed system
2. Version Tracking: Maintain complete version history  
3. Directory Structure: Proper S3-compatible path organization
4. Metadata Integrity: Keep indexes and references synchronized
5. Error Recovery: Cleanup partial operations on failures
So yes, a single S3 PUT request can trigger 4-6 different write operations depending on the versioning configuration, each targeting different storage components for consistency and S3 compatibility!